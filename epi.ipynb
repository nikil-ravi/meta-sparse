{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import types\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scene_net import *\n",
    "\n",
    "TASKS_NUM_CLASS = [40, 3, 1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_parameters(model):\n",
    "    # Function to count the number of parameters in each layer of a PyTorch model\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Size: {param.size()} | Count: {param.numel()}\")\n",
    "\n",
    "    for name, param in model.named_buffers():\n",
    "        print(f\"Layer: {name} | Size: {param.size()} | Count: {param.numel()}\")\n",
    "\n",
    "# Create an instance of the network\n",
    "net = SceneNet(TASKS_NUM_CLASS).to(device)\n",
    "#net.load_state_dict(torch.load(\"/home/nravi/DiSparse-Multitask-Model-Compression/results_new/best_nyuv2_baseline.pth\"))\n",
    "\n",
    "\n",
    "# Count the parameters\n",
    "#count_parameters(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pruned_init(net):\n",
    "    for module in net.modules():\n",
    "        # Check if it's basic block\n",
    "        if isinstance(module, nn.modules.conv.Conv2d) or isinstance(module, nn.modules.Linear):\n",
    "            module = prune.identity(module, 'weight')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sim(mask1, mask2, sal1 = None, sal2 = None, sim_metric = \"epi\"):\n",
    "\n",
    "    n1 = torch.count_nonzero(mask1).item()\n",
    "    n2 = torch.count_nonzero(mask2).item()\n",
    "    \n",
    "    if sim_metric == \"epi\":\n",
    "        similarity = 1 - (abs(n1 - n2) / (n1 + n2))\n",
    "    elif sim_metric == \"iou\":\n",
    "        intersection = torch.logical_and(mask1, mask2)\n",
    "        union = torch.logical_or(mask1, mask2)\n",
    "        similarity = torch.count_nonzero(intersection) / torch.count_nonzero(union)\n",
    "    elif sim_metric == \"sals\":\n",
    "        similarity = torch.nn.functional.cosine_similarity(sal1.flatten(), sal2.flatten(), dim=0, eps=1e-8)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(numbers):\n",
    "    n = len(numbers)\n",
    "    weights = []\n",
    "    for i in range(n):\n",
    "        #weights.append(n-i)\n",
    "        weights.append(1)\n",
    "    sum = 0\n",
    "    weights_sum = 0\n",
    "    for weight, val in zip(weights, numbers):\n",
    "        sum += weight * val\n",
    "        weights_sum += weight\n",
    "    return sum/weights_sum\n",
    "\n",
    "def subnet_similarity(mask1, mask2, sal1, sal2, model):\n",
    "    epi_scores = []\n",
    "    count = 0\n",
    "\n",
    "    for (name, module) in model.named_modules():\n",
    "        if (isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear)) and (\"backbone\" in name):\n",
    "            params = module.parameters()\n",
    "            epi_scores.append(layer_sim(mask1[count].bool(), mask2[count].bool(), sal1[count], sal2[count], sim_metric=\"sals\"))\n",
    "            count += 1\n",
    "    \n",
    "    return weighted_average(epi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pairwise_similarities(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        salmasks = pickle.load(file)\n",
    "    keepmasks = salmasks[\"masks\"]\n",
    "    sals = salmasks[\"sals\"]\n",
    "    \n",
    "    similarity_dict = {}\n",
    "    for task1 in keepmasks:\n",
    "        for task2 in keepmasks:\n",
    "            if task2 + task1 in similarity_dict:\n",
    "                continue\n",
    "            similarity_dict[task1+task2] = subnet_similarity(keepmasks[task1], keepmasks[task2], sals[task1], sals[task2], net)\n",
    "    \n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depthdepth': tensor(1., device='cuda:0'),\n",
      " 'segdepth': tensor(0.7736, device='cuda:0'),\n",
      " 'segseg': tensor(1., device='cuda:0'),\n",
      " 'segsn': tensor(0.7702, device='cuda:0'),\n",
      " 'sndepth': tensor(0.7658, device='cuda:0'),\n",
      " 'snsn': tensor(1., device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "pprint.PrettyPrinter(width=20).pprint(all_pairwise_similarities(\"sal_masks_static.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('cs330env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d1c73999476ce146966cebe8b07995064b32ca3b7ccbb387005b845d6d615d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
